import os
import json
import urllib.parse
from dotenv import load_dotenv
from google import genai
from google.genai import types
from supabase import create_client, Client

# 1. í™˜ê²½ ì„¤ì • íŒŒì¼(.env) ë¡œë“œ
load_dotenv()
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY")
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
COUPANG_PARTNER_ID = os.environ.get("COUPANG_PARTNER_ID")

# --- í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ---
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
gemini_client = genai.Client(api_key=GEMINI_API_KEY)


# --- 2. Gemini ìš”ì²­ JSON ìŠ¤í‚¤ë§ˆ ---
SCHEMA = {
    # ... (V5ì™€ ë™ì¼í•œ JSON ìŠ¤í‚¤ë§ˆ ë‚´ìš©) ...
    "type": "object",
    "properties": {
        "title": {"type": "string", "description": "ì œëª© ìµœì í™” (ì˜ˆ: [ë°±ì¢…ì›] ê¹€ì¹˜ì°Œê°œ)"},
        "summary": {"type": "string", "description": "15ì ì´ë‚´ì˜ í•œ ì¤„ ìš”ì•½"},
        "ingredients_json": {
            "type": "array",
            "items": {
                "type": "object",
                "properties": {
                    "name": {"type": "string"},
                    "amount": {"type": "string", "description": "g ë˜ëŠ” ml ë‹¨ìœ„ë¡œ í‘œê¸° (ì˜ˆ: 300g)"}
                },
                "required": ["name", "amount"]
            },
            "description": "ìš”ë¦¬ì— í•„ìš”í•œ í•µì‹¬ ì¬ë£Œ ëª©ë¡ ë° ê³„ëŸ‰"
        },
        "method_text": {"type": "string", "description": "ìˆ«ì(1, 2, 3...)ë¥¼ ë¶™ì¸ ê°„ê²°í•œ ì¡°ë¦¬ ìˆœì„œ"},
        "tips": {"type": "string", "description": "ì‰í”„ê°€ ê°•ì¡°í•œ ìš”ë¦¬ íŒ"},
        "group_id": {"type": "string", "description": "ë©”ë‰´ ê·¸ë£¹ ID (ì˜ˆ: Kimchi_Jjigae)"},
        "tags": {"type": "array", "items": {"type": "string"}, "description": "ìƒí™©ë³„, ì¬ë£Œë³„ íƒœê·¸ (ì˜ˆ: í•œì‹, ì°Œê°œ, ë¼ì§€ê³ ê¸°)"},
        "video_url": {"type": "string", "description": "ì°¸ê³ í•œ ìœ íŠœë¸Œ ì˜ìƒ URL ì£¼ì†Œ"} 
    },
    "required": ["title", "summary", "ingredients_json", "method_text", "tags", "video_url"]
}


# --- 3. ì¿ íŒ¡ ê²€ìƒ‰ ë§í¬ ìƒì„± í•¨ìˆ˜ ---
def generate_coupang_search_link(ingredient_name: str, partner_id: str) -> str:
    search_term = urllib.parse.quote_plus(ingredient_name)
    return f"https://www.coupang.com/np/search?q={search_term}&channel=affiliate&affid={partner_id}"


def run_snap_crawler_v6(search_query: str):
    """ë‹¨ì¼ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•˜ê³  ë°ì´í„°ë¥¼ ìˆ˜ì§‘ ë° ì €ì¥í•©ë‹ˆë‹¤."""
    print(f"--- ğŸ” '{search_query}' ê²€ìƒ‰ ì‹œì‘ ---")
    
    try:
        # 1) Geminiì—ê²Œ ë ˆì‹œí”¼ ì •ë³´ ìš”ì²­
        prompt = (
            f"ìœ íŠœë¸Œë‚˜ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì†ŒìŠ¤ì—ì„œ '{search_query}'ì˜ ë ˆì‹œí”¼ë¥¼ ë¶„ì„í•´. "
            f"ê²°ê³¼ë¬¼ì— ë°˜ë“œì‹œ ì´ ë ˆì‹œí”¼ì˜ **ìœ íŠœë¸Œ ì˜ìƒ URL**ì„ í¬í•¨í•˜ê³ , "
            f"ë‚´ê°€ ì •ì˜í•œ SCHEMAì— ë§ì¶° JSON í˜•ì‹ìœ¼ë¡œë§Œ í•œêµ­ì–´ë¡œ ì¶œë ¥í•´ì¤˜. "
            f"ì¬ë£Œ ì–‘ì€ ìµœëŒ€í•œ 'g' ë‹¨ìœ„ë¡œ ë³€í™˜í•´ì¤˜."
        )
        
        response = gemini_client.models.generate_content(
            model='gemini-2.5-flash', 
            contents=prompt,
            config=types.GenerateContentConfig(
                response_mime_type="application/json",
                response_schema=SCHEMA
            )
        )
        
        ai_data = json.loads(response.text)
        
        # 2) ì¬ë£Œ JSONì— ì¿ íŒ¡ ë§í¬ ì‚½ì… (ìˆ˜ìµí™” ë¡œì§)
        modified_ingredients = []
        for item in ai_data['ingredients_json']:
            ingredient_name = item['name']
            item['purchase_link'] = generate_coupang_search_link(ingredient_name, COUPANG_PARTNER_ID) 
            modified_ingredients.append(item)
        
        # 3) DBì— ì €ì¥í•  ìµœì¢… ë°ì´í„° êµ¬ì¡°
        final_data = {
            "title": ai_data['title'],
            "summary": ai_data['summary'],
            "ingredients_json": modified_ingredients,
            "method_text": ai_data['method_text'],
            "tips": ai_data.get('tips', 'ë³„ë„ íŒ ì—†ìŒ'),
            "group_id": ai_data['group_id'],
            "tags": ai_data['tags'],
            "video_url": ai_data['video_url'],
            "restaurant_name": None,
            "store_link": None
        }
        
        # 4) Supabase DBì— ë°ì´í„° ì‚½ì…
        supabase.table('recipes').insert(final_data).execute()
        
        print(f"--- âœ… '{final_data['title']}' ì €ì¥ ì„±ê³µ! ---")
        return True # ì„±ê³µ ë°˜í™˜
        
    except Exception as e:
        error_message = str(e)
        print(f"âŒ '{search_query}' ë°ì´í„° ì²˜ë¦¬ ë˜ëŠ” ì €ì¥ ì‹¤íŒ¨: {error_message}")
        return False # ì‹¤íŒ¨ ë°˜í™˜


# --- ì‹¤í–‰ ë¶€ë¶„ (chef_list.txt íŒŒì¼ ì½ì–´ì„œ ì „ì²´ ì‹¤í–‰) ---
if __name__ == "__main__":
    if not all([SUPABASE_URL, SUPABASE_KEY, GEMINI_API_KEY, COUPANG_PARTNER_ID]):
        print("âŒ ì˜¤ë¥˜: .env íŒŒì¼ì— í‚¤ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤. í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    else:
        try:
            # chef_list.txt íŒŒì¼ì—ì„œ ì¿¼ë¦¬ ëª©ë¡ì„ ì½ì–´ì˜µë‹ˆë‹¤.
            with open('chef_list.txt', 'r', encoding='utf-8') as f:
                search_queries = [line.strip() for line in f if line.strip()]
            
            print(f"\n--- ğŸ¤– Snap Food ë¡œë´‡ V6 ê°€ë™: ì´ {len(search_queries)}ê°œ ì¿¼ë¦¬ ì‹¤í–‰ ---")
            
            success_count = 0
            fail_count = 0
            
            for query in search_queries:
                if run_snap_crawler_v6(query):
                    success_count += 1
                else:
                    fail_count += 1

            print(f"\n=======================================================")
            print(f"ğŸ‰ ë°°ì¹˜ ì‘ì—… ì™„ë£Œ: ì„±ê³µ {success_count}ê°œ, ì‹¤íŒ¨ {fail_count}ê°œ")
            print(f"=======================================================")

        except FileNotFoundError:
            print("âŒ ì˜¤ë¥˜: 'chef_list.txt' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ìƒì„±í–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        except Exception as e:
            print(f"âŒ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")